{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "from functions import show, put_labels\n",
    "\n",
    "from constants import *\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_features(lt,j=2):\n",
    "    lt = [lt[i] for i in range(len(lt)) if i%j==0]\n",
    "    return lt\n",
    "\n",
    "def filter_features(fd):\n",
    "    return [f for f in fd if len(f)==2048]\n",
    "\n",
    "def filter_region(region):\n",
    "    width = region[2] - region[0]\n",
    "    height = region[3] - region[1]\n",
    "    # Incorrect region\n",
    "    if width==0 or height==0:\n",
    "        print \"Incorrect region\",region\n",
    "        return True\n",
    "    # distorted rects\n",
    "#     if width / height > 4 or height / width > 4:\n",
    "#         return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_positives = np.load('cat_vs_dogs_positives.npy')\n",
    "\n",
    "#get dicts from numpy array\n",
    "class_positives = class_positives[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filtering 538 389\n",
      "after filtering 538 389\n"
     ]
    }
   ],
   "source": [
    "dog = class_positives['dog']\n",
    "cat = class_positives['cat']\n",
    "print 'before filtering',len(dog),len(cat)\n",
    "dog = filter_features(dog)\n",
    "cat = filter_features(cat)\n",
    "print 'after filtering',len(dog),len(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract train data\n",
    "X = []\n",
    "X.extend(dog)\n",
    "y = [1]*len(dog)\n",
    "X.extend(cat)\n",
    "y.extend([0]*len(cat))   \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract(image,box=None):\n",
    "    \"\"\"Returns hog feature descriptor for an image.\n",
    "    \"\"\"\n",
    "    #print 'initial',image.shape\n",
    "    #print len(image)\n",
    "    if box is not None:\n",
    "        image = image[box[0]:box[2],box[1]:box[3]]\n",
    "    \n",
    "    #resize image\n",
    "    #print image.shape\n",
    "    #print len(image)\n",
    "    image = resize(image)\n",
    "    #print image.shape\n",
    "    #image = color.rgb2gray(img)\n",
    "    fd = hog(image, orientations=8, pixels_per_cell=(image.shape[1]/16, image.shape[0]/16),\n",
    "                    cells_per_block=(1, 1), visualise=False, transform_sqrt=True)\n",
    "    #print len(fd)\n",
    "    return fd\n",
    "\n",
    "def resize(image):\n",
    "    if image.shape[1]/image.shape[0] >= 2:\n",
    "        image = cv2.resize(image,(128,64))\n",
    "    elif float(image.shape[1])/image.shape[0] <= 0.5:\n",
    "        image = cv2.resize(image,(64,128))\n",
    "    else:\n",
    "        image = cv2.resize(image,(128,128))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dog': (48, 240, 195, 371)}, {'person': (8, 12, 352, 498)}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load test data\n",
    "test_ground_truth = np.load('test_ground_truth.npy')\n",
    "test_ground_truth[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extract test data\n",
    "d = {'cat':0,'dog':1}\n",
    "Xtest,ytest = list(),list()\n",
    "imgs,i_boxes = list(),list()\n",
    "for i in range(len(test_ground_truth)):\n",
    "    boxes = list()\n",
    "    for dt in test_ground_truth[i][1]:\n",
    "        if 'dog' in dt or 'cat' in dt:\n",
    "            if filter_region(dt.values()[0]):\n",
    "                print dt\n",
    "            else:\n",
    "                boxes.append(dt)\n",
    "    if len(boxes)!=0:\n",
    "        name = test_ground_truth[i][0]\n",
    "        imgs.append(name)\n",
    "        i_boxes.append(boxes)\n",
    "        img = cv2.imread(folder_test + '/' + name,0)\n",
    "        #print name,boxes\n",
    "        for box in boxes:\n",
    "            #print box.values()[0]\n",
    "            p_box = box.values()[0]\n",
    "            p_box = p_box[1::-1] + p_box[3:1:-1] \n",
    "            Xtest.append(extract(img,p_box))\n",
    "            ytest.append(d[box.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for cat vs dogs\n",
      "Feature Vectors: 927\n",
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print 'Training for cat vs dogs'\n",
    "print 'Feature Vectors:',len(X)\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],'gamma':[0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']}\n",
    "clf = GridSearchCV(svm.SVC(probability=True,class_weight='balanced'), param_grid,n_jobs=3)\n",
    "clf = clf.fit(X, y)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "# clf = svm.SVC(gamma=0.01, C=100,probability=True)\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 89  61]\n",
      " [ 66 171]]\n",
      "Accuracy: 0.6718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.59      0.58       150\n",
      "          1       0.74      0.72      0.73       237\n",
      "\n",
      "avg / total       0.67      0.67      0.67       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i_boxes = [[(94,1,442,374)],[(126,51,330,308)],[(48,240,195,371),(8,12,352,498)],[(31,30,358,279)],[(63,18,374,500)]]\n",
    "# imgs = [cv2.imread('Cat vs Dog Data/000442.jpg',0),cv2.imread('Cat vs Dog Data/000011.jpg',0),\n",
    "#         cv2.imread('000001.jpg',0),cv2.imread('Cat vs Dog Data/000018.jpg',0),\n",
    "#         cv2.imread('Cat vs Dog Data/000028.jpg',0)]\n",
    "pred = clf.predict(Xtest)\n",
    "from sklearn import metrics\n",
    "print(\"Confusion matrix:\\n%s\" %metrics.confusion_matrix(ytest,pred))\n",
    "print(\"Accuracy: %0.4f\" % metrics.accuracy_score(ytest,pred))\n",
    "print \"{0}\".format(metrics.classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_01.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_02.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_03.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_04.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_05.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_06.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_07.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_08.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_09.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_10.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_11.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_12.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_13.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_14.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_15.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_16.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_17.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_18.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_19.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_20.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_21.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_22.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_23.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_24.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_25.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_26.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_27.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_28.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_29.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_30.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_31.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_32.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_33.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_34.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_35.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_36.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_37.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_38.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_39.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_40.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_41.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_42.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_43.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_44.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_45.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_46.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_47.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_48.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_49.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_50.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_51.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_52.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_53.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_54.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_55.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_56.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_57.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_58.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_59.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_60.npy',\n",
       " 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl_61.npy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib \n",
    "joblib.dump(clf, 'Cats Vs Dogs Classifier/cat_pos_vs_dog_pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_class(clf,imgs,i_boxes):\n",
    "    # if boxes is None:\n",
    "    from extract import extract\n",
    "    d = {0:'cat',1:'dog'}\n",
    "    for img,boxes in zip(imgs,i_boxes):\n",
    "        labels = []\n",
    "        show(img)\n",
    "        for box in boxes:\n",
    "            print box\n",
    "            input = extract(img,box)\n",
    "#             print clf.predict_proba([input])\n",
    "            labels.append(d[clf.predict([input])[0]])\n",
    "        print labels\n",
    "        put_labels(img,boxes,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_regions = np.load('test_regns.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_detections(detections):\n",
    "    detections = sorted(detections,key = lambda detection:detection[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect region (285, 499, 405, 499)\n",
      "Incorrect region (285, 499, 405, 499)\n",
      "Incorrect region (404, 0, 404, 111)\n",
      "Incorrect region (405, 0, 405, 190)\n",
      "Incorrect region (405, 0, 405, 189)\n",
      "Incorrect region (404, 0, 404, 111)\n",
      "Incorrect region (68, 19, 187, 19)\n",
      "Incorrect region (67, 6, 207, 6)\n",
      "Incorrect region (66, 20, 192, 20)\n",
      "Incorrect region (75, 50, 177, 50)\n",
      "Incorrect region (71, 152, 209, 152)\n",
      "Incorrect region (70, 149, 199, 149)\n",
      "Incorrect region (67, 6, 181, 6)\n",
      "Incorrect region (68, 19, 208, 19)\n",
      "Incorrect region (66, 20, 235, 20)\n",
      "Incorrect region (67, 6, 181, 6)\n",
      "Incorrect region (89, 23, 273, 23)\n",
      "Incorrect region (75, 126, 177, 126)\n",
      "Incorrect region (75, 126, 177, 126)\n",
      "Incorrect region (70, 149, 198, 149)\n",
      "Incorrect region (75, 50, 177, 50)\n",
      "Incorrect region (61, 22, 217, 22)\n",
      "Incorrect region (66, 20, 219, 20)\n",
      "Incorrect region (93, 22, 217, 22)\n",
      "Incorrect region (76, 125, 176, 125)\n",
      "Incorrect region (71, 152, 209, 152)\n",
      "Incorrect region (76, 126, 176, 126)\n",
      "Incorrect region (71, 152, 208, 152)\n",
      "Incorrect region (71, 151, 206, 151)\n",
      "Incorrect region (82, 23, 273, 23)\n",
      "Incorrect region (133, 24, 273, 24)\n",
      "Incorrect region (298, 211, 298, 353)\n",
      "Incorrect region (297, 212, 297, 353)\n",
      "Incorrect region (299, 245, 299, 353)\n",
      "Incorrect region (298, 212, 298, 353)\n",
      "Incorrect region (289, 209, 289, 320)\n",
      "Incorrect region (293, 209, 293, 353)\n",
      "Incorrect region (297, 222, 297, 353)\n",
      "Incorrect region (295, 210, 295, 353)\n",
      "Incorrect region (296, 211, 296, 353)\n",
      "Incorrect region (295, 210, 295, 353)\n",
      "Incorrect region (297, 208, 297, 353)\n",
      "Incorrect region (296, 212, 296, 353)\n",
      "Incorrect region (298, 212, 298, 353)\n",
      "Incorrect region (295, 211, 295, 353)\n",
      "Incorrect region (295, 212, 295, 353)\n",
      "Incorrect region (289, 209, 289, 308)\n",
      "Incorrect region (299, 245, 299, 353)\n",
      "Incorrect region (297, 212, 297, 353)\n",
      "Incorrect region (299, 245, 299, 353)\n",
      "Incorrect region (295, 210, 295, 353)\n",
      "Incorrect region (299, 245, 299, 353)\n",
      "Incorrect region (298, 212, 298, 353)\n",
      "Incorrect region (296, 204, 296, 353)\n",
      "Incorrect region (295, 210, 295, 353)\n",
      "Incorrect region (287, 320, 287, 483)\n",
      "Incorrect region (286, 389, 286, 499)\n",
      "Incorrect region (286, 389, 286, 499)\n",
      "Incorrect region (293, 318, 293, 499)\n",
      "Incorrect region (241, 296, 241, 412)\n",
      "Incorrect region (286, 391, 286, 499)\n",
      "Incorrect region (293, 388, 293, 499)\n",
      "Incorrect region (294, 316, 294, 493)\n",
      "Incorrect region (294, 318, 294, 499)\n",
      "Incorrect region (294, 316, 294, 499)\n",
      "Incorrect region (287, 320, 287, 499)\n",
      "Incorrect region (241, 0, 241, 175)\n",
      "Incorrect region (294, 388, 294, 499)\n",
      "Incorrect region (292, 389, 292, 499)\n",
      "Incorrect region (292, 318, 292, 499)\n",
      "Incorrect region (241, 0, 241, 137)\n",
      "Incorrect region (241, 295, 241, 411)\n",
      "Incorrect region (296, 316, 296, 481)\n",
      "Incorrect region (293, 388, 293, 499)\n",
      "Incorrect region (240, 297, 240, 422)\n",
      "Incorrect region (109, 49, 252, 49)\n",
      "Incorrect region (110, 26, 221, 26)\n",
      "Incorrect region (110, 49, 220, 49)\n",
      "Incorrect region (109, 49, 252, 49)\n",
      "Incorrect region (110, 50, 250, 50)\n",
      "Incorrect region (0, 485, 142, 485)\n",
      "Incorrect region (0, 485, 283, 485)\n",
      "Incorrect region (143, 485, 285, 485)\n",
      "Incorrect region (143, 484, 286, 484)\n",
      "Incorrect region (0, 485, 142, 485)\n",
      "Incorrect region (0, 485, 255, 485)\n",
      "Incorrect region (143, 484, 287, 484)\n",
      "Incorrect region (40, 484, 142, 484)\n",
      "Incorrect region (143, 485, 499, 485)\n",
      "Incorrect region (40, 484, 142, 484)\n",
      "Incorrect region (143, 484, 283, 484)\n",
      "Incorrect region (256, 485, 499, 485)\n",
      "Incorrect region (40, 484, 142, 484)\n",
      "Incorrect region (143, 484, 283, 484)\n",
      "Incorrect region (40, 484, 140, 484)\n",
      "Incorrect region (256, 485, 499, 485)\n",
      "Incorrect region (40, 484, 142, 484)\n",
      "Incorrect region (286, 484, 499, 484)\n",
      "Incorrect region (258, 485, 499, 485)\n",
      "Incorrect region (287, 484, 499, 484)\n",
      "Incorrect region (284, 484, 499, 484)\n",
      "Incorrect region (288, 484, 498, 484)\n",
      "Incorrect region (144, 485, 257, 485)\n",
      "Incorrect region (286, 485, 499, 485)\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "for dt in test_regions:\n",
    "    name = path.join(folder_test,dt.keys()[0])\n",
    "    img = cv2.imread(name,0)\n",
    "    regions = dt.values()[0]\n",
    "    probs,labels = list(),list()\n",
    "    regions = [region for region in regions if not filter_region(region)]\n",
    "    for regn in regions:\n",
    "        fd = extract(img,regn)\n",
    "        probs.append(max(clf.predict_proba([fd])[0]))\n",
    "        labels.append(clf.predict([fd]))\n",
    "    detections = zip(regions,probs,labels)\n",
    "    detections = filter_detections(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "extract(imgs[0],[10,10,100,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [1, 2], [3, 5]]\n"
     ]
    }
   ],
   "source": [
    "filter_detections([[1,2],[2,1],[3,5]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
