{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib \n",
    "from functions import show\n",
    "\n",
    "from skimage import data, color, exposure\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/media/arjun/New Volume/Code/Research/Summer Stream Project/Content Based Image Retrieval/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract(image,box=None):\n",
    "    \"\"\"Returns hog feature descriptor for an image.\n",
    "    \"\"\"\n",
    "    if box is not None:\n",
    "        image = image[box[0]:box[2],box[1]:box[3]]\n",
    "        \n",
    "    #image = color.rgb2gray(img)\n",
    "    fd = hog(image, orientations=8, pixels_per_cell=(image.shape[1]/16, image.shape[0]/16),\n",
    "                    cells_per_block=(1, 1), visualise=False, transform_sqrt=True)\n",
    "\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "#     ax1.axis('off')\n",
    "#     ax1.imshow(image, cmap=plt.cm.gray)\n",
    "#     ax1.set_title('Input image')\n",
    "#     ax1.set_adjustable('box-forced')\n",
    "\n",
    "#     # Rescale histogram for better display\n",
    "#     hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))\n",
    "\n",
    "#     ax2.axis('off')\n",
    "#     ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "#     ax2.set_title('Histogram of Oriented Gradients')\n",
    "#     ax1.set_adjustable('box-forced')\n",
    "#     plt.show()\n",
    "    #print len(fd)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bus,dinosaur,rose, elephant,horse= [],[],[],[],[]\n",
    "\n",
    "for i in range(500,560):\n",
    "    elephant.append(extract(cv2.imread(path+str(i)+'.jpg',0)))\n",
    "\n",
    "for i in range(700,760):\n",
    "    horse.append(extract(cv2.imread(path+str(i)+'.jpg',0)))\n",
    "\n",
    "for i in range(600,660):\n",
    "    rose.append(extract(cv2.imread(path+str(i)+'.jpg',0)))\n",
    "    \n",
    "for i in range(400,460):\n",
    "    dinosaur.append(extract(cv2.imread(path+str(i)+'.jpg',0)))\n",
    "    \n",
    "for i in range(300,360):\n",
    "    bus.append(extract(cv2.imread(path+str(i)+'.jpg',0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Feature Vectors: 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "X.extend(elephant)\n",
    "y = [4]*len(elephant)\n",
    "X.extend(horse)\n",
    "y.extend([3]*len(horse))\n",
    "X.extend(rose)\n",
    "y.extend([2]*len(rose))\n",
    "X.extend(dinosaur)\n",
    "y.extend([1]*len(dinosaur))\n",
    "X.extend(bus)\n",
    "y.extend([0]*len(bus))   \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print 'Training'\n",
    "print 'Feature Vectors:',len(X)\n",
    "[i for i in range(len(X)) if len(X[i])!=2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],'gamma':[0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']}\n",
    "clf = GridSearchCV(svm.SVC(class_weight='balanced'), param_grid,n_jobs=2)\n",
    "clf = clf.fit(X, y)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "# clf = svm.SVC(gamma=0.001, C=100,probability=True)\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest = [extract(cv2.imread(path+str(i)+'.jpg',0)) for i in range(660,692)]\n",
    "ytest = [2]*len(Xtest)\n",
    "\n",
    "Xtest.extend([extract(cv2.imread(path+str(i)+'.jpg',0)) for i in range(560,585)])\n",
    "ytest.extend([4]*len(range(560,585)))\n",
    "\n",
    "Xtest.extend([extract(cv2.imread(path+str(i)+'.jpg',0)) for i in range(760,799)])\n",
    "ytest.extend([3]*len(range(760,799)))\n",
    "\n",
    "Xtest.extend([extract(cv2.imread(path+str(i)+'.jpg',0)) for i in range(360,390)])\n",
    "ytest.extend([0]*len(range(360,390)))\n",
    "Xtest.extend([extract(cv2.imread(path+str(i)+'.jpg',0)) for i in range(460,495)])\n",
    "ytest.extend([1]*len(range(460,495)))\n",
    "pred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[29  0  0  0  1]\n",
      " [ 0 35  0  0  0]\n",
      " [ 0  0 28  1  3]\n",
      " [ 0  0  0 39  0]\n",
      " [ 0  0  0  4 21]]\n",
      "Accuracy: 0.9441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        30\n",
      "          1       1.00      1.00      1.00        35\n",
      "          2       1.00      0.88      0.93        32\n",
      "          3       0.89      1.00      0.94        39\n",
      "          4       0.84      0.84      0.84        25\n",
      "\n",
      "avg / total       0.95      0.94      0.94       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Confusion matrix:\\n%s\" %metrics.confusion_matrix(ytest,pred))\n",
    "print(\"Accuracy: %0.4f\" % metrics.accuracy_score(ytest,pred))\n",
    "print \"{0}\".format(metrics.classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92333333333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
